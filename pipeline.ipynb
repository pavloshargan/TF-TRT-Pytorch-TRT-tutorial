{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-TRT/Pytorch-TRT tutorial\n",
    "<p>This tutorial describes steps how to convert your tensorflow saved model to TensorRT engine and how to run it on video. You can also folow the same steps if you have Pytorch model, the difference is only in the first step (converting to ONNX)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There steps are:\n",
    "* Convert saved model to ONNX using tf2onnx python library\n",
    "* Simplify ONNX model using onnxsimplifier python library\n",
    "* Copy siplified ONNX model from your PC to Jetson\n",
    "* Create TensorRT engine from ONNX model on the Jetson using trtexec\n",
    "* Adjust given script for inferencing(change the model shape, output names, adjust input preprocesing and output processing), and run the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert saved model to ONNX using tf2onnx python library (skip if you have Pytorch model):\n",
    "<p> Install tf2onnx:  </p>\n",
    "```console\n",
    "pavlo@pc:~$ pip3 install tf2onnx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Convert tf saved model to onnx: </p> \n",
    "\n",
    "```\n",
    "pavlo@pc:~$ python3 -m tf2onnx.convert --saved-model \"my_tf_saved_model\" --output \"my_model.onnx\" --opset 11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have Pytorch model, convert it to onnx using folowing example:\n",
    "```\n",
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "# A model class instance (class not shown)\n",
    "model = MyModelClass()\n",
    "\n",
    "# Load the weights from a file (.pth usually)\n",
    "state_dict = torch.load(weights_path)\n",
    "\n",
    "# Load the weights now into a model net architecture defined by our class\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Create the right input shape (e.g. for an image)\n",
    "dummy_input = torch.randn(sample_batch_size, channel, height, width)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"my_model.onnx\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify ONNX model using onnxsimplifier python library:\n",
    "<p> Install onnxsimplifyer: </p>\n",
    "    \n",
    "```console\n",
    "pavlo@pc:~$ pip3 install onnxsim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Simplify onnx model: </p> \n",
    "\n",
    "```\n",
    "pavlo@pc:~$ python3 -m onnxsim my_model.onnx my_model_simpl.onnx --input-shape 1,224,224,3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Now copy my_model_simpl.onnx to Jetson device </p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TensorRT engine from ONNX model:\n",
    "```console\n",
    "jetson@myjetsonnano:~$ /usr/src/tensorrt/bin/trtexec --onnx=/home/myjetsonnano/Desktop/Projects/trt_tutorial/my_model_simpl.onnx --shapes=\\'input_1:0\\':1x224x224x3 --saveEngine=/home/myjetsonnano/Desktop/Projects/trt_tutorial/engine.trt --verbose --explicitBatch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies on Jetson to run the script for inferencing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```console\n",
    "export PATH=/usr/local/cuda-10.2/bin:$PATH\n",
    "export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH\n",
    "sudo apt install python3-pip\n",
    "pip3 install cyton\n",
    "pip3 install pycuda\n",
    "sudo apt-get libprotobuf-dev\n",
    "sudo apt-get protobuf-compiler\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Open run_model.py and edit input name, input shape and path to the video:</p>\n",
    "\n",
    "![screenshot1](./screenshot.jpg)\n",
    "\n",
    "<p> add data preprocessing if needed:</p>\n",
    "![screenshot1](./screenshot1.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <b>Now run the script! </b></p>\n",
    "<p>P.S if your model has 2 outputs, you should uncoment commented lines</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
